---
title: "Analysis of The IKEA Furniture Price"
author: 'Group 21-Ananth Padakannaya,Nivedita Patil,Li Wang,Wanqing Yang,Boyao Ma'
date: "06/07/2021"
output:
  pdf_document:
    latex_engine: pdflatex
    number_sections: yes
  html_document:
    df_print: paged
  word_document: default
fig_caption: yes
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA)
```

```{r library}
library(tidyverse)
library(tinytex)
library(sjPlot)
library(jtools)
library(car)
library(reshape2)
library(kableExtra)
library(mice)
library(VIM)
library(ROCR)
library(moderndive)
library(gapminder)
library(stats)
library(gridExtra)
```

```{r data, echo = FALSE, eval = TRUE}
ikea.sa <- read_csv("dataset21.csv")
```

# Introduction{#sec:Intro}
Data set provided is from Ikea (Saudi Arabia), It is of interest to determine which properties of a furniture determine where the price is greater than 1000 riyals.

# Exploratory Data Analysis {#sec:EDA}
```{r exploratory,echo = FALSE, eval = TRUE}
ikea.sa<-mutate(ikea.sa,price_level=if_else(price>1000,1,0))
summary(ikea.sa[4:10]) %>%
kable(caption = '\\label{tab:summaries} Summary statistics for observations with chosen variables.') %>%
  kable_styling(latex_options = "hold_position", full_width = F, font_size = 8)
```
We first took 1000 as a dividing point according to the problem, and added a new list of binary variables named price_level. Furniture with a price greater than 1000 takes 1, otherwise it takes 0. Then we performed descriptive statistical analysis based on these selected variables....(Then write some analysis)

# Visualization of the data {#sec:VIS}
```{r histogram,echo = FALSE, eval = TRUE}
Encoding(ikea.sa$category)<-"ASCII"
ggplot(ikea.sa, aes(x = factor(category), fill = factor(price_level))) +
geom_bar(stat="count", position = "stack")+
  ylab("Number of furnitures")+xlab("Category")+scale_x_discrete(labels = abbreviate)+
theme(legend.position = "right") +
    theme(legend.direction = "vertical") +
    theme(axis.text.x = element_text(angle = 90))
```
```{r exploratory ,echo = FALSE, eval = TRUE}
library(plotly)

fig <- plot_ly(ikea.sa, x = ~width, y = ~height, text = ~category, type = 'scatter', mode = 'markers',color=~category,
        marker = list(size = ~depth/10, opacity = 0.5))
fig <- fig %>% layout(title = 'Distribution of Furniture Dimensions',
         xaxis = list(showgrid = FALSE),
         yaxis = list(showgrid = FALSE))
fig
```
# Formal Data Analysis {#sec:FDA}
```{r aggrplot,echo = FALSE, eval = TRUE,out.width = '70%', fig.pos = 'H', fig.align = "center", fig.cap = "\\label{fig:aggr} Missing original data."}
aggr(ikea.sa)
```
Through the above figure, we found that there are many missing values and the missing data is mainly concentrated in three explanatory variables, namely depth, length and width. And the three horizontal red squares indicate that these three data are missing at the same time. If we ignore or delete these missing data directly, it will have a great impact on the analysis of the data. So we have to use multiple imputation to fill in missing data.

```{r stripplot,echo = FALSE, eval = TRUE,out.width = '70%', fig.pos = 'H', fig.align = "center", fig.cap = "\\label{fig:strip} Data situation of multiple imputation method."}
#interpolation for missing values
imp<-mice(ikea.sa[,7:9],seed=1234)
stripplot(imp,pch=19,cex=1.2,alpha=.3)
imp<-mice(ikea.sa[,3:10],seed=1234)
ikea<-complete(imp,action = 4)
```

According to the picture, we can view the data interpolation. The blue point is the original data, and the red point is the interpolation data. We can see that the two color points are relatively overlapped, indicating that the interpolation is very good.Then we chose the fourth database of multiple imputation for generalized linear model analysis.

```{r glm,echo = FALSE, eval = TRUE}
#fit model
fit<-glm(price_level~sellable_online+other_colors+depth+height+width,data=ikea,family=binomial(link="logit"))
summary(fit)
```
We use price_level as the response variable. Because it is a binary variable, so we can use a logistic regression model for the probability of whether the price is greater than 1000. Through the above table, we found that the P values of the two categorical variables(sellable_online and other_colors) are both greater than 0.05, so it means that these two items are not significant in this model, and we need to eliminate these two variables. Next, we use the remaining variables to perform a new modeling.

$$log({\widehat{\mbox{p}}_{\mbox{i}}\over{1-\widehat{\mbox{p}}_{\mbox{i}}}} )= \widehat{\alpha}+{\widehat\beta}*{\mbox{depth}}_{\mbox{i}}+\widehat{\gamma}*{\mbox{height}}_{\mbox{i}}+\widehat{\delta}*{\mbox{width}}_{\mbox{i}}$$

where

• the $\widehat{\mbox{p}}_{\mbox{i}}$:  the probability of whether the price is greater than 1000 for the $i\mbox{th}$ furniture.

• the $\widehat{\alpha}$: the intercept of the regression line.

• the $\widehat{\beta}$: the coefficient for the first explanatory variable ${\mbox{depth}}$.

• the $\widehat{\gamma}$: the coefficient for the second explanatory variable ${\mbox{height}}$.

• the $\widehat{\delta}$: the coefficient for the second explanatory variable ${\mbox{width}}$.

When this model is fitted to the data, the following estimates of ${\alpha}$  (intercept) and ${\beta}$,${\gamma}$ and ${\delta}$ are returned:
```{r,echo = FALSE, eval = TRUE}
#reject insignificant explanatory variables and fit into new model
final<-glm(price_level~depth+height+width,data=ikea,family=binomial(link="logit"))
summary(final)
```
According to the coefficients in the above table, we can get the final model as follows:
$$log({\widehat{\mbox{p}}_{\mbox{i}}\over{1-\widehat{\mbox{p}}_{\mbox{i}}}} )=-7.3421+0.0469*{\mbox{depth}}_{\mbox{i}}+0.0122*{\mbox{height}}_{\mbox{i}}+0.0229*{\mbox{width}}_{\mbox{i}}$$

This is equivalent to:
$$\widehat{\mbox{p}}_{\mbox{i}}={exp(-7.3421+0.0469*{\mbox{depth}}_{\mbox{i}}+0.0122*{\mbox{height}}_{\mbox{i}}+0.0229*{\mbox{width}}_{\mbox{i}})\over1+exp(-7.3421+0.0469*{\mbox{depth}}_{\mbox{i}}+0.0122*{\mbox{height}}_{\mbox{i}}+0.0229*{\mbox{width}}_{\mbox{i}})}$$

Lily(write something to explain this formula)

```{r,echo = FALSE, eval = TRUE}
confint(final) %>%
  kable(caption = '\\label{tab:CI} The confidence interval of variables.') %>%
  kable_styling(latex_options = "hold_position")
```
(write something to explain this CI)


```{r,echo = FALSE, eval = TRUE}
final %>%
 coef() %>%
  exp()%>%
  kable(caption = '\\label{tab:summaries} Odds scale.') %>%
  kable_styling(latex_options = "hold_position")
```
On the odds scale, the intercept value (0.00006477) gives the probability that the price is greater than 1000 when depth= 0, width=0 and height=0. This is obviously not the feasible range of depth, width and height, so why this value is very close to zero. For depth, we There is a probability of 1.05, which means that for each increase in depth by 1 unit, the probability that the furniture price is greater than 1000 increases by 1.06 times. For each unit of the same height, the probability increases by 1.01 times. For each unit increase in width, the probability increases by 1.02 times.

```{r oddsplots,echo=FALSE, fig.align = "center",fig.cap = "\\label{fig:odds} Odds ratios of three explanatory variables.", fig.pos = 'H', message = FALSE}
plot_model(final, show.values = TRUE, axis.lim = c(1,1.5),
           title = "Odds (price over 1000 furniture)", show.p = FALSE)
```
We can also see the graphic about......(lily)


```{r residplots,echo=FALSE, fig.align = "center",fig.cap = "\\label{fig:resids} Probability of price over 1000 by three different variables.", fig.pos = 'H', message = FALSE}
ikea <- ikea %>%
          mutate(probs.price = fitted(final))
g1<-ggplot(data = ikea, aes(x = depth, y = probs.price)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "depth", y = "Probability of price over 1000")
g2<-ggplot(data = ikea, aes(x = height, y = probs.price)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "height", y = "Probability of price over 1000")
g3<-ggplot(data = ikea, aes(x = width, y = probs.price)) +
  geom_smooth(method="glm", 
              method.args = list(family="binomial"), 
              se = FALSE) +
  labs(x = "width", y = "Probability of price over 1000")
grid.arrange(g1,g2,g3,ncol = 2)
```


lily...

# Goodness of fit
```{r ROCplots,echo=FALSE, fig.align = "center",fig.cap = "\\label{fig:ROC} ROC curve.", fig.pos = 'H', message = FALSE}
prob <- predict(final,newdata=ikea, type="response")
pred <- prediction(prob, ikea$price_level)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2) +
    geom_line(aes(y=tpr)) + 
    ggtitle(paste0("ROC Curve w/ AUC=", auc))

```
explain ROC and AUC

# Conclusions and Future Works
# References

